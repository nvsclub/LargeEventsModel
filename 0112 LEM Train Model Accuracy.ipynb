{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.data_utils import *\n",
    "from lib.model_utils import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'ACC'\n",
    "MODEL_NAME = f'LEMv4_MODEL_{MODEL_TYPE}_TORCH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_train_y, df_optimization, df_optimization_y, df_test, df_test_y, complete_feature_set, features_model = load_model_training_data_template(train_sets = ['data/wyscout/csv/events/Italy.csv', 'data/wyscout/csv/events/Germany.csv', 'data/wyscout/csv/events/France.csv'], optimization_sets = ['data/wyscout/csv/events/Italy.csv',], test_sets = ['data/wyscout/csv/events/Spain.csv', 'data/wyscout/csv/events/England.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_train_y[MODEL_TYPE].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_model[MODEL_TYPE]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[features].astype(float).values\n",
    "x_optimization = df_optimization[features].astype(float).values\n",
    "X_test = df_test[features].astype(float).values\n",
    "\n",
    "Y_train = df_train_y[MODEL_TYPE].astype(float).values\n",
    "Y_optimization = df_optimization_y[MODEL_TYPE].astype(float).values\n",
    "Y_test = df_test_y[MODEL_TYPE].astype(float).values\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_optimization_tensor = torch.tensor(x_optimization, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_optimization_tensor = torch.tensor(Y_optimization, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "optimization_dataset = TensorDataset(X_optimization_tensor, Y_optimization_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "optimization_dataloader = DataLoader(optimization_dataset, batch_size=1024, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = Y_train.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_TUNING = False\n",
    "TUNNING_COMPLEXITY_PENALTY = 0.001\n",
    "TUNNING_TRAIN_TEST_SPLIT = 0.7\n",
    "TUNNING_N_TRIALS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_TUNING:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, X_optimization_tensor, Y_optimization_tensor, model_name=MODEL_NAME, train_test_split=TUNNING_TRAIN_TEST_SPLIT, complexity_penalty=TUNNING_COMPLEXITY_PENALTY), n_trials=TUNNING_N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_TUNING:\n",
    "    trial = study.best_trial\n",
    "    print(trial.value, trial.params, trial.datetime_start, trial.datetime_complete)\n",
    "    \n",
    "    model = torch.load(f'models/lem/optuna_trials/{MODEL_NAME}_{trial.number}.pt')\n",
    "    test_log_loss = evaluate_log_loss(model, optimization_dataloader, device)\n",
    "    print(f'Test Log Loss: {test_log_loss:.4f}')\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "    plt.subplot(121)\n",
    "    probabilities = predict(model, X_optimization_tensor, device)\n",
    "    plt.hist(probabilities, bins=50);\n",
    "    plt.subplot(122)\n",
    "    plt.hist(probabilities[:,1], bins=50, color='C1')\n",
    "    plt.yscale('log');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLayerBinaryClassifier(input_size, [128], output_size, activation='sigmoid').to(device)\n",
    "learning_rate = 0.0410\n",
    "num_epochs = 100\n",
    "patience = 3\n",
    "counter = 0\n",
    "best_val_loss = 1000\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "    test_loss = evaluate(model, test_dataloader, criterion, device)\n",
    "    test_log_loss = evaluate_log_loss(model, test_dataloader, device)\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}.. Training loss: {train_loss:.4f}.. Test loss: {test_loss:.4f}.. Test Log Loss: {test_log_loss:.4f}')\n",
    "\n",
    "    if test_log_loss < best_val_loss:\n",
    "        best_val_loss = test_log_loss\n",
    "        counter = 0\n",
    "        torch.save(model, f'models/lem/{MODEL_NAME}.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10.6, 6.8)\n",
    "plt.subplot(121)\n",
    "probabilities = predict(model, X_test_tensor, device)\n",
    "plt.hist(probabilities, bins=25);\n",
    "plt.subplot(122)\n",
    "plt.hist(probabilities[:, 1], bins=25);\n",
    "plt.yscale('log');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
