{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.data_utils import *\n",
    "from lib.model_utils import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'TYPE'\n",
    "MODEL_NAME = f'LEMv3_MODEL_{MODEL_TYPE}_TORCH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_train_y, df_optimization, df_optimization_y, df_test, df_test_y, complete_feature_set, features_model = load_model_training_data_template(train_sets = ['data/wyscout/csv/events/Italy.csv', 'data/wyscout/csv/events/Germany.csv', 'data/wyscout/csv/events/France.csv'], optimization_sets = ['data/wyscout/csv/events/Italy.csv',], test_sets = ['data/wyscout/csv/events/Spain.csv', 'data/wyscout/csv/events/England.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['next_action_type_1', 'next_action_type_2', 'next_action_type_3', 'next_action_type_4', 'next_action_type_5', 'next_action_type_6', 'next_action_type_7', 'next_action_type_8', 'next_action_type_9', 'next_action_type_10', 'next_action_type_11', 'next_action_type_12', 'next_action_type_13', 'next_action_type_14', 'next_action_type_15', 'next_action_type_16', 'next_action_type_17', 'next_action_type_18', 'next_action_type_19', 'next_action_type_20', 'next_action_type_21', 'next_action_type_22', 'next_action_type_23', 'next_action_type_24', 'next_action_type_25', 'next_action_type_26', 'next_action_type_27', 'next_action_type_28', 'next_action_type_29', 'next_action_type_30', 'next_action_type_31', 'next_action_type_32', 'next_action_type_33']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_train_y[MODEL_TYPE].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subtype_id_1', 'subtype_id_2', 'subtype_id_3', 'subtype_id_4', 'subtype_id_5', 'subtype_id_6', 'subtype_id_7', 'subtype_id_8', 'subtype_id_9', 'subtype_id_10', 'subtype_id_11', 'subtype_id_12', 'subtype_id_13', 'subtype_id_14', 'subtype_id_15', 'subtype_id_16', 'subtype_id_17', 'subtype_id_18', 'subtype_id_19', 'subtype_id_20', 'subtype_id_21', 'subtype_id_22', 'subtype_id_23', 'subtype_id_24', 'subtype_id_25', 'subtype_id_26', 'subtype_id_27', 'subtype_id_28', 'subtype_id_29', 'subtype_id_30', 'subtype_id_31', 'subtype_id_32', 'subtype_id_33', 'period', 'minute', 'x', 'y', 'is_home_team', 'accurate', 'goal', 'home_score', 'away_score']\n"
     ]
    }
   ],
   "source": [
    "features = features_model[MODEL_TYPE]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[features].astype(float).values\n",
    "x_optimization = df_optimization[features].astype(float).values\n",
    "X_test = df_test[features].astype(float).values\n",
    "\n",
    "Y_train = df_train_y[MODEL_TYPE].astype(float).values\n",
    "Y_optimization = df_optimization_y[MODEL_TYPE].astype(float).values\n",
    "Y_test = df_test_y[MODEL_TYPE].astype(float).values\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_optimization_tensor = torch.tensor(x_optimization, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_optimization_tensor = torch.tensor(Y_optimization, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "optimization_dataset = TensorDataset(X_optimization_tensor, Y_optimization_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "optimization_dataloader = DataLoader(optimization_dataset, batch_size=256, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = Y_train.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_TUNING = True\n",
    "TUNNING_COMPLEXITY_PENALTY = 0.001\n",
    "TUNNING_TRAIN_TEST_SPLIT = 0.7\n",
    "TUNNING_N_TRIALS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-10 18:10:39,929]\u001b[0m A new study created in memory with name: no-name-1f8e2524-9fd3-4776-9b0f-0a1a0e690a71\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:13:51,470]\u001b[0m Trial 0 finished with value: 1.5263919666502737 and parameters: {'hidden_size': 1, 'hidden_size_0': 4, 'hidden_size_1': 4, 'hidden_size_2': 5, 'lr': 0.010777963650332883, 'batch_size': 5, 'activation': 'sigmoid'}. Best is trial 0 with value: 1.5263919666502737.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:15:00,842]\u001b[0m Trial 1 finished with value: 2.318062956872209 and parameters: {'hidden_size': 3, 'hidden_size_0': 4, 'hidden_size_1': 8, 'hidden_size_2': 4, 'lr': 0.06890242028807815, 'batch_size': 7, 'activation': 'tanh'}. Best is trial 0 with value: 1.5263919666502737.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:16:26,050]\u001b[0m Trial 2 finished with value: 2.025414994316115 and parameters: {'hidden_size': 2, 'hidden_size_0': 7, 'hidden_size_1': 5, 'hidden_size_2': 7, 'lr': 0.04956725313836901, 'batch_size': 6, 'activation': 'sigmoid'}. Best is trial 0 with value: 1.5263919666502737.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:17:42,452]\u001b[0m Trial 3 finished with value: 2.2866976958849174 and parameters: {'hidden_size': 3, 'hidden_size_0': 5, 'hidden_size_1': 8, 'hidden_size_2': 4, 'lr': 0.013572723814885336, 'batch_size': 6, 'activation': 'tanh'}. Best is trial 0 with value: 1.5263919666502737.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:20:51,038]\u001b[0m Trial 4 finished with value: 1.5162138233411009 and parameters: {'hidden_size': 2, 'hidden_size_0': 6, 'hidden_size_1': 4, 'hidden_size_2': 8, 'lr': 0.009855691743544944, 'batch_size': 8, 'activation': 'tanh'}. Best is trial 4 with value: 1.5162138233411009.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:23:47,833]\u001b[0m Trial 5 finished with value: 1.7188600404769552 and parameters: {'hidden_size': 3, 'hidden_size_0': 7, 'hidden_size_1': 7, 'hidden_size_2': 5, 'lr': 0.015630759638789644, 'batch_size': 9, 'activation': 'tanh'}. Best is trial 4 with value: 1.5162138233411009.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:24:34,768]\u001b[0m Trial 6 finished with value: 1.927343133363565 and parameters: {'hidden_size': 3, 'hidden_size_0': 7, 'hidden_size_1': 6, 'hidden_size_2': 4, 'lr': 0.09666119562719984, 'batch_size': 7, 'activation': 'relu'}. Best is trial 4 with value: 1.5162138233411009.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:27:05,204]\u001b[0m Trial 7 finished with value: 1.528448864066993 and parameters: {'hidden_size': 2, 'hidden_size_0': 5, 'hidden_size_1': 8, 'hidden_size_2': 5, 'lr': 0.032105743781406376, 'batch_size': 10, 'activation': 'tanh'}. Best is trial 4 with value: 1.5162138233411009.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:28:04,511]\u001b[0m Trial 8 finished with value: 3.7301718976040257 and parameters: {'hidden_size': 2, 'hidden_size_0': 8, 'hidden_size_1': 6, 'hidden_size_2': 6, 'lr': 0.09532832299779179, 'batch_size': 6, 'activation': 'tanh'}. Best is trial 4 with value: 1.5162138233411009.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:29:12,343]\u001b[0m Trial 9 finished with value: 20.313325692193747 and parameters: {'hidden_size': 3, 'hidden_size_0': 7, 'hidden_size_1': 4, 'hidden_size_2': 8, 'lr': 0.060349475580673724, 'batch_size': 8, 'activation': 'tanh'}. Best is trial 4 with value: 1.5162138233411009.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:31:33,864]\u001b[0m Trial 10 finished with value: 1.4921191543592043 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 5, 'hidden_size_2': 8, 'lr': 0.006857453693145558, 'batch_size': 9, 'activation': 'relu'}. Best is trial 10 with value: 1.4921191543592043.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:34:43,086]\u001b[0m Trial 11 finished with value: 1.4906648631675807 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 5, 'hidden_size_2': 8, 'lr': 0.003893146245145807, 'batch_size': 9, 'activation': 'relu'}. Best is trial 11 with value: 1.4906648631675807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:47:48,608]\u001b[0m Trial 12 finished with value: 1.5126569021966425 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 5, 'hidden_size_2': 7, 'lr': 0.0004406093339150664, 'batch_size': 10, 'activation': 'relu'}. Best is trial 11 with value: 1.4906648631675807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:49:19,675]\u001b[0m Trial 13 finished with value: 1.5224638006553874 and parameters: {'hidden_size': 1, 'hidden_size_0': 5, 'hidden_size_1': 5, 'hidden_size_2': 7, 'lr': 0.030420707866937333, 'batch_size': 9, 'activation': 'relu'}. Best is trial 11 with value: 1.4906648631675807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:51:00,066]\u001b[0m Trial 14 finished with value: 1.5046408848177013 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 5, 'hidden_size_2': 8, 'lr': 0.027596900053821576, 'batch_size': 9, 'activation': 'relu'}. Best is trial 11 with value: 1.4906648631675807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 18:52:05,772]\u001b[0m Trial 15 finished with value: 1.527113231991252 and parameters: {'hidden_size': 1, 'hidden_size_0': 5, 'hidden_size_1': 6, 'hidden_size_2': 7, 'lr': 0.023651221638112712, 'batch_size': 9, 'activation': 'relu'}. Best is trial 11 with value: 1.4906648631675807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:06:17,194]\u001b[0m Trial 16 finished with value: 1.4916700622883712 and parameters: {'hidden_size': 1, 'hidden_size_0': 8, 'hidden_size_1': 7, 'hidden_size_2': 8, 'lr': 0.00035953945132454444, 'batch_size': 10, 'activation': 'relu'}. Best is trial 11 with value: 1.4906648631675807.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:10:01,961]\u001b[0m Trial 17 finished with value: 1.4866794321717023 and parameters: {'hidden_size': 1, 'hidden_size_0': 8, 'hidden_size_1': 7, 'hidden_size_2': 6, 'lr': 0.002650957700477786, 'batch_size': 10, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:12:42,515]\u001b[0m Trial 18 finished with value: 1.4990188996708709 and parameters: {'hidden_size': 2, 'hidden_size_0': 8, 'hidden_size_1': 7, 'hidden_size_2': 6, 'lr': 0.018676852669482488, 'batch_size': 10, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:13:57,760]\u001b[0m Trial 19 finished with value: 1.5037144553754065 and parameters: {'hidden_size': 1, 'hidden_size_0': 7, 'hidden_size_1': 7, 'hidden_size_2': 6, 'lr': 0.03789218852611222, 'batch_size': 8, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:15:13,661]\u001b[0m Trial 20 finished with value: 1.5078924939549558 and parameters: {'hidden_size': 2, 'hidden_size_0': 8, 'hidden_size_1': 6, 'hidden_size_2': 7, 'lr': 0.021195520651624434, 'batch_size': 10, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:24:44,828]\u001b[0m Trial 21 finished with value: 1.489681807796335 and parameters: {'hidden_size': 1, 'hidden_size_0': 8, 'hidden_size_1': 7, 'hidden_size_2': 6, 'lr': 0.0006132980586164201, 'batch_size': 10, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:30:15,163]\u001b[0m Trial 22 finished with value: 1.490847308434137 and parameters: {'hidden_size': 1, 'hidden_size_0': 8, 'hidden_size_1': 7, 'hidden_size_2': 6, 'lr': 0.0009152116169676944, 'batch_size': 10, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:32:27,280]\u001b[0m Trial 23 finished with value: 1.4909456131013112 and parameters: {'hidden_size': 1, 'hidden_size_0': 7, 'hidden_size_1': 7, 'hidden_size_2': 6, 'lr': 0.007408882584819602, 'batch_size': 9, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:34:28,698]\u001b[0m Trial 24 finished with value: 1.4932689933194894 and parameters: {'hidden_size': 1, 'hidden_size_0': 8, 'hidden_size_1': 8, 'hidden_size_2': 5, 'lr': 0.019309634493651497, 'batch_size': 10, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:36:15,688]\u001b[0m Trial 25 finished with value: 1.4941094434971058 and parameters: {'hidden_size': 1, 'hidden_size_0': 7, 'hidden_size_1': 6, 'hidden_size_2': 6, 'lr': 0.008792730453907894, 'batch_size': 9, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:38:17,262]\u001b[0m Trial 26 finished with value: 1.4923913363399581 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 7, 'hidden_size_2': 5, 'lr': 0.015849332605230197, 'batch_size': 8, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:53:24,889]\u001b[0m Trial 27 finished with value: 1.548071300447489 and parameters: {'hidden_size': 2, 'hidden_size_0': 8, 'hidden_size_1': 6, 'hidden_size_2': 7, 'lr': 2.5616796041766365e-05, 'batch_size': 10, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:55:20,778]\u001b[0m Trial 28 finished with value: 1.4909804468569356 and parameters: {'hidden_size': 1, 'hidden_size_0': 7, 'hidden_size_1': 8, 'hidden_size_2': 6, 'lr': 0.0076414804248794346, 'batch_size': 9, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 19:59:23,258]\u001b[0m Trial 29 finished with value: 1.4904957158363772 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 4, 'hidden_size_2': 5, 'lr': 0.011596071277330118, 'batch_size': 10, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:02:07,617]\u001b[0m Trial 30 finished with value: 1.529234271161687 and parameters: {'hidden_size': 1, 'hidden_size_0': 4, 'hidden_size_1': 4, 'hidden_size_2': 5, 'lr': 0.01198932787664843, 'batch_size': 5, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:08:24,109]\u001b[0m Trial 31 finished with value: 1.4916645697513526 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 4, 'hidden_size_2': 6, 'lr': 0.005855890999991831, 'batch_size': 10, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:10:58,806]\u001b[0m Trial 32 finished with value: 1.5125368364845548 and parameters: {'hidden_size': 1, 'hidden_size_0': 5, 'hidden_size_1': 4, 'hidden_size_2': 4, 'lr': 0.0141391473570075, 'batch_size': 10, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:13:39,434]\u001b[0m Trial 33 finished with value: 1.4947184689559352 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 5, 'hidden_size_2': 5, 'lr': 0.02380110841627984, 'batch_size': 10, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:18:26,333]\u001b[0m Trial 34 finished with value: 1.4914370508005401 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 4, 'hidden_size_2': 6, 'lr': 0.004982139636006806, 'batch_size': 9, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:21:50,683]\u001b[0m Trial 35 finished with value: 1.5182235823055015 and parameters: {'hidden_size': 2, 'hidden_size_0': 4, 'hidden_size_1': 5, 'hidden_size_2': 4, 'lr': 0.012754134691649129, 'batch_size': 10, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:23:10,673]\u001b[0m Trial 36 finished with value: 1.5019541679769566 and parameters: {'hidden_size': 1, 'hidden_size_0': 6, 'hidden_size_1': 8, 'hidden_size_2': 5, 'lr': 0.0127589461342104, 'batch_size': 8, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:24:45,313]\u001b[0m Trial 37 finished with value: 1.4968341152090647 and parameters: {'hidden_size': 1, 'hidden_size_0': 7, 'hidden_size_1': 6, 'hidden_size_2': 7, 'lr': 0.00516887716651274, 'batch_size': 7, 'activation': 'relu'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:28:05,475]\u001b[0m Trial 38 finished with value: 1.500720657977279 and parameters: {'hidden_size': 2, 'hidden_size_0': 5, 'hidden_size_1': 5, 'hidden_size_2': 7, 'lr': 0.018800949084044356, 'batch_size': 9, 'activation': 'sigmoid'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 20:30:19,687]\u001b[0m Trial 39 finished with value: 1.5079787236549818 and parameters: {'hidden_size': 1, 'hidden_size_0': 7, 'hidden_size_1': 7, 'hidden_size_2': 4, 'lr': 0.03751058030494133, 'batch_size': 10, 'activation': 'tanh'}. Best is trial 17 with value: 1.4866794321717023.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if ENABLE_TUNING:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, X_optimization_tensor, Y_optimization_tensor, model_name=MODEL_NAME, train_test_split=TUNNING_TRAIN_TEST_SPLIT, complexity_penalty=TUNNING_COMPLEXITY_PENALTY), n_trials=TUNNING_N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4866794321717023 {'hidden_size': 1, 'hidden_size_0': 8, 'hidden_size_1': 7, 'hidden_size_2': 6, 'lr': 0.002650957700477786, 'batch_size': 10, 'activation': 'relu'} 2023-05-10 19:06:17.196895 2023-05-10 19:10:01.961199\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/lem/optuna_trials/LEMv3_MODEL_TYPE_TORCH_17.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m trial \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_trial\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(trial\u001b[39m.\u001b[39mvalue, trial\u001b[39m.\u001b[39mparams, trial\u001b[39m.\u001b[39mdatetime_start, trial\u001b[39m.\u001b[39mdatetime_complete)\n\u001b[1;32m----> 5\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodels/lem/optuna_trials/\u001b[39;49m\u001b[39m{\u001b[39;49;00mMODEL_NAME\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mtrial\u001b[39m.\u001b[39;49mnumber\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m test_log_loss \u001b[39m=\u001b[39m evaluate_log_loss(model, optimization_dataloader, device)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest Log Loss: \u001b[39m\u001b[39m{\u001b[39;00mtest_log_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nvs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\nvs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\nvs\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/lem/optuna_trials/LEMv3_MODEL_TYPE_TORCH_17.pt'"
     ]
    }
   ],
   "source": [
    "if ENABLE_TUNING:\n",
    "    trial = study.best_trial\n",
    "    print(trial.value, trial.params, trial.datetime_start, trial.datetime_complete)\n",
    "    \n",
    "    model = torch.load(f'models/lem/optuna_trials/{MODEL_NAME}_{trial.number}.pt')\n",
    "    test_log_loss = evaluate_log_loss(model, optimization_dataloader, device)\n",
    "    print(f'Test Log Loss: {test_log_loss:.4f}')\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "    plt.subplot(121)\n",
    "    probabilities = predict(model, X_optimization_tensor, device)\n",
    "    plt.hist(probabilities, bins=50);\n",
    "    plt.subplot(122)\n",
    "    plt.hist(probabilities[:,1], bins=50, color='C1')\n",
    "    plt.yscale('log');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100.. Training loss: 0.0517.. Test loss: 0.0487.. Test Log Loss: 9.2654\n",
      "Epoch: 2/100.. Training loss: 0.0482.. Test loss: 0.0480.. Test Log Loss: 9.1255\n",
      "Epoch: 3/100.. Training loss: 0.0478.. Test loss: 0.0477.. Test Log Loss: 9.0757\n",
      "Epoch: 4/100.. Training loss: 0.0476.. Test loss: 0.0475.. Test Log Loss: 9.0360\n",
      "Epoch: 5/100.. Training loss: 0.0474.. Test loss: 0.0474.. Test Log Loss: 9.0042\n",
      "Epoch: 6/100.. Training loss: 0.0472.. Test loss: 0.0473.. Test Log Loss: 8.9854\n",
      "Epoch: 7/100.. Training loss: 0.0471.. Test loss: 0.0472.. Test Log Loss: 8.9657\n",
      "Epoch: 8/100.. Training loss: 0.0470.. Test loss: 0.0471.. Test Log Loss: 8.9547\n",
      "Epoch: 9/100.. Training loss: 0.0470.. Test loss: 0.0470.. Test Log Loss: 8.9402\n",
      "Epoch: 10/100.. Training loss: 0.0469.. Test loss: 0.0470.. Test Log Loss: 8.9332\n",
      "Epoch: 11/100.. Training loss: 0.0468.. Test loss: 0.0469.. Test Log Loss: 8.9192\n",
      "Epoch: 12/100.. Training loss: 0.0468.. Test loss: 0.0469.. Test Log Loss: 8.9153\n",
      "Epoch: 13/100.. Training loss: 0.0467.. Test loss: 0.0468.. Test Log Loss: 8.9040\n",
      "Epoch: 14/100.. Training loss: 0.0467.. Test loss: 0.0468.. Test Log Loss: 8.8936\n",
      "Epoch: 15/100.. Training loss: 0.0466.. Test loss: 0.0467.. Test Log Loss: 8.8848\n",
      "Epoch: 16/100.. Training loss: 0.0466.. Test loss: 0.0467.. Test Log Loss: 8.8818\n",
      "Epoch: 17/100.. Training loss: 0.0466.. Test loss: 0.0467.. Test Log Loss: 8.8729\n",
      "Epoch: 18/100.. Training loss: 0.0465.. Test loss: 0.0466.. Test Log Loss: 8.8695\n",
      "Epoch: 19/100.. Training loss: 0.0465.. Test loss: 0.0466.. Test Log Loss: 8.8632\n",
      "Epoch: 20/100.. Training loss: 0.0465.. Test loss: 0.0466.. Test Log Loss: 8.8578\n",
      "Epoch: 21/100.. Training loss: 0.0464.. Test loss: 0.0466.. Test Log Loss: 8.8591\n",
      "Epoch: 22/100.. Training loss: 0.0464.. Test loss: 0.0465.. Test Log Loss: 8.8511\n",
      "Epoch: 23/100.. Training loss: 0.0464.. Test loss: 0.0465.. Test Log Loss: 8.8476\n",
      "Epoch: 24/100.. Training loss: 0.0464.. Test loss: 0.0465.. Test Log Loss: 8.8422\n",
      "Epoch: 25/100.. Training loss: 0.0463.. Test loss: 0.0465.. Test Log Loss: 8.8416\n",
      "Epoch: 26/100.. Training loss: 0.0463.. Test loss: 0.0465.. Test Log Loss: 8.8395\n",
      "Epoch: 27/100.. Training loss: 0.0463.. Test loss: 0.0464.. Test Log Loss: 8.8349\n",
      "Epoch: 28/100.. Training loss: 0.0463.. Test loss: 0.0464.. Test Log Loss: 8.8337\n",
      "Epoch: 29/100.. Training loss: 0.0463.. Test loss: 0.0464.. Test Log Loss: 8.8356\n",
      "Epoch: 30/100.. Training loss: 0.0463.. Test loss: 0.0464.. Test Log Loss: 8.8292\n",
      "Epoch: 31/100.. Training loss: 0.0462.. Test loss: 0.0464.. Test Log Loss: 8.8247\n",
      "Epoch: 32/100.. Training loss: 0.0462.. Test loss: 0.0464.. Test Log Loss: 8.8259\n",
      "Epoch: 33/100.. Training loss: 0.0462.. Test loss: 0.0464.. Test Log Loss: 8.8262\n",
      "Epoch: 34/100.. Training loss: 0.0462.. Test loss: 0.0463.. Test Log Loss: 8.8188\n",
      "Epoch: 35/100.. Training loss: 0.0462.. Test loss: 0.0463.. Test Log Loss: 8.8178\n",
      "Epoch: 36/100.. Training loss: 0.0462.. Test loss: 0.0463.. Test Log Loss: 8.8164\n",
      "Epoch: 37/100.. Training loss: 0.0462.. Test loss: 0.0463.. Test Log Loss: 8.8178\n",
      "Epoch: 38/100.. Training loss: 0.0461.. Test loss: 0.0463.. Test Log Loss: 8.8137\n",
      "Epoch: 39/100.. Training loss: 0.0461.. Test loss: 0.0463.. Test Log Loss: 8.8112\n",
      "Epoch: 40/100.. Training loss: 0.0461.. Test loss: 0.0463.. Test Log Loss: 8.8101\n",
      "Epoch: 41/100.. Training loss: 0.0461.. Test loss: 0.0463.. Test Log Loss: 8.8080\n",
      "Epoch: 42/100.. Training loss: 0.0461.. Test loss: 0.0463.. Test Log Loss: 8.8066\n",
      "Epoch: 43/100.. Training loss: 0.0461.. Test loss: 0.0463.. Test Log Loss: 8.8083\n",
      "Epoch: 44/100.. Training loss: 0.0461.. Test loss: 0.0463.. Test Log Loss: 8.8048\n",
      "Epoch: 45/100.. Training loss: 0.0461.. Test loss: 0.0463.. Test Log Loss: 8.8034\n",
      "Epoch: 46/100.. Training loss: 0.0461.. Test loss: 0.0463.. Test Log Loss: 8.8095\n",
      "Epoch: 47/100.. Training loss: 0.0460.. Test loss: 0.0462.. Test Log Loss: 8.8018\n",
      "Epoch: 48/100.. Training loss: 0.0460.. Test loss: 0.0462.. Test Log Loss: 8.8019\n",
      "Epoch: 49/100.. Training loss: 0.0460.. Test loss: 0.0462.. Test Log Loss: 8.7982\n",
      "Epoch: 50/100.. Training loss: 0.0460.. Test loss: 0.0462.. Test Log Loss: 8.7985\n",
      "Epoch: 51/100.. Training loss: 0.0460.. Test loss: 0.0462.. Test Log Loss: 8.7958\n",
      "Epoch: 52/100.. Training loss: 0.0460.. Test loss: 0.0462.. Test Log Loss: 8.8023\n",
      "Epoch: 53/100.. Training loss: 0.0460.. Test loss: 0.0462.. Test Log Loss: 8.7969\n",
      "Epoch: 54/100.. Training loss: 0.0460.. Test loss: 0.0462.. Test Log Loss: 8.7970\n"
     ]
    }
   ],
   "source": [
    "model = MultiLayerBinaryClassifier(input_size, [256, 256, 256], output_size).to(device)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "patience = 3\n",
    "counter = 0\n",
    "best_val_loss = 1000\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "    test_loss = evaluate(model, test_dataloader, criterion, device)\n",
    "    test_log_loss = evaluate_log_loss(model, test_dataloader, device)\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}.. Training loss: {train_loss:.4f}.. Test loss: {test_loss:.4f}.. Test Log Loss: {test_log_loss:.4f}')\n",
    "\n",
    "    if test_log_loss < best_val_loss:\n",
    "        best_val_loss = test_log_loss\n",
    "        counter = 0\n",
    "        torch.save(model, f'models/lem/{MODEL_NAME}.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1060x680 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10.6, 6.8)\n",
    "probabilities = predict(model, X_test_tensor, device)\n",
    "plt.hist(probabilities, bins=25);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
